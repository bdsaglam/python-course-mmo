{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-Output (IO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/file_open_modes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('workfile.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('The first line\\n')\n",
    "f.write('The second line\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.writelines(['The third line', \"The fourth line\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('unifile.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('abcdeığüşç')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Take a comma-separated words string and write each word to new-line in a file.\n",
    "\n",
    "Input: 'black, blue, green, magenta, pink, red'\n",
    "\n",
    "Expected output: \n",
    "```\n",
    "black\n",
    "blue\n",
    "green\n",
    "magenta\n",
    "pink\n",
    "red\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('workfile.txt', 'r')\n",
    "text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first line\\nThe second line\\nThe third lineThe fourth lineupdate string'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('workfile.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first line\\nThe second line\\nThe third lineThe fourth lineupdate string'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The first line',\n",
       " 'The second line',\n",
       " 'The third lineThe fourth lineupdate string']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('workfile.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first line\n",
      "\n",
      "The second line\n",
      "\n",
      "The third line\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Write a Python program to read first n lines of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('workfile.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' first lin'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.seek?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "can't do nonzero cur-relative seeks",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c13f4f83800d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: can't do nonzero cur-relative seeks"
     ]
    }
   ],
   "source": [
    "# to use other seek modes the file must be opened in byte mode\n",
    "f.seek(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-6b7481d6d1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to use other seek modes the file must be opened in byte mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# to use other seek modes the file must be opened in byte mode\n",
    "f.seek(-5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('unifile.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcde'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ığüşç'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Byte mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('unifile.txt', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abcde\\xc4\\xb1\\xc4\\x9f\\xc3\\xbc\\xc5\\x9f\\xc3\\xa7'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abcde'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xc4\\xb1\\xc4\\x9f\\xc3\\xbc\\xc5\\x9f\\xc3\\xa7'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ığüşç'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[5:].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('ığüşç')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xc4\\xb1\\xc4\\x9f\\xc3\\xbc\\xc5\\x9f\\xc3\\xa7'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ığüşç'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xc4\\xb1\\xc4\\x9f\\xc3\\xbc\\xc5\\x9f\\xc3\\xa7'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ığüşç'.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abcd123,.*?'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'abcd123,.*?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "bytes can only contain ASCII literal characters. (<ipython-input-122-05bad91d8059>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-122-05bad91d8059>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    b'çğşö'\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m bytes can only contain ASCII literal characters.\n"
     ]
    }
   ],
   "source": [
    "b'çğşö'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('bytefile', 'wb')\n",
    "f.write(b'0123456789abcdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('bytefile', 'rb+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.seek?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(5)      # Go to the 6th byte in the file\n",
    "f.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'd'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(-3, 2)  # Go to the 3rd byte before the end\n",
    "f.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first line\n",
      "\n",
      "The second line\n",
      "\n",
      "The third line\n"
     ]
    }
   ],
   "source": [
    "with open('workfile.txt') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Write a program that reads first and last 10 bytes from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('workfile.txt', 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first line\\nThe second line\\nThe third lineThe fourth line'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('update string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first line\\nThe second line\\nThe third lineThe fourth lineupdate string'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Write a program that puts line number in front of each line of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StringIO in module io:\n",
      "\n",
      "class StringIO(_TextIOBase)\n",
      " |  Text I/O implementation using an in-memory buffer.\n",
      " |  \n",
      " |  The initial_value argument sets the value of object.  The newline\n",
      " |  argument is like the one of TextIOWrapper's constructor.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StringIO\n",
      " |      _TextIOBase\n",
      " |      _IOBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __next__(self, /)\n",
      " |      Implement next(self).\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |  \n",
      " |  close(self, /)\n",
      " |      Close the IO object.\n",
      " |      \n",
      " |      Attempting any further operation after the object is closed\n",
      " |      will raise a ValueError.\n",
      " |      \n",
      " |      This method has no effect if the file is already closed.\n",
      " |  \n",
      " |  getvalue(self, /)\n",
      " |      Retrieve the entire contents of the object.\n",
      " |  \n",
      " |  read(self, size=None, /)\n",
      " |      Read at most size characters, returned as a string.\n",
      " |      \n",
      " |      If the argument is negative or omitted, read until EOF\n",
      " |      is reached. Return an empty string at EOF.\n",
      " |  \n",
      " |  readable(self, /)\n",
      " |      Returns True if the IO object can be read.\n",
      " |  \n",
      " |  readline(self, size=None, /)\n",
      " |      Read until newline or EOF.\n",
      " |      \n",
      " |      Returns an empty string if EOF is hit immediately.\n",
      " |  \n",
      " |  seek(self, pos, whence=0, /)\n",
      " |      Change stream position.\n",
      " |      \n",
      " |      Seek to character offset pos relative to position indicated by whence:\n",
      " |          0  Start of stream (the default).  pos should be >= 0;\n",
      " |          1  Current position - pos must be 0;\n",
      " |          2  End of stream - pos must be 0.\n",
      " |      Returns the new absolute position.\n",
      " |  \n",
      " |  seekable(self, /)\n",
      " |      Returns True if the IO object can be seeked.\n",
      " |  \n",
      " |  tell(self, /)\n",
      " |      Tell the current file position.\n",
      " |  \n",
      " |  truncate(self, pos=None, /)\n",
      " |      Truncate size to pos.\n",
      " |      \n",
      " |      The pos argument defaults to the current file position, as\n",
      " |      returned by tell().  The current file position is unchanged.\n",
      " |      Returns the new absolute position.\n",
      " |  \n",
      " |  writable(self, /)\n",
      " |      Returns True if the IO object can be written.\n",
      " |  \n",
      " |  write(self, s, /)\n",
      " |      Write string to file.\n",
      " |      \n",
      " |      Returns the number of characters written, which is always equal to\n",
      " |      the length of the string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  closed\n",
      " |  \n",
      " |  line_buffering\n",
      " |  \n",
      " |  newlines\n",
      " |      Line endings translated so far.\n",
      " |      \n",
      " |      Only line endings translated during reading are considered.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _TextIOBase:\n",
      " |  \n",
      " |  detach(...)\n",
      " |      Separate the underlying buffer from the TextIOBase and return it.\n",
      " |      \n",
      " |      After the underlying buffer has been detached, the TextIO is in an\n",
      " |      unusable state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _TextIOBase:\n",
      " |  \n",
      " |  encoding\n",
      " |      Encoding of the text stream.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  errors\n",
      " |      The error setting of the decoder or encoder.\n",
      " |      \n",
      " |      Subclasses should override.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _IOBase:\n",
      " |  \n",
      " |  __del__(...)\n",
      " |  \n",
      " |  __enter__(...)\n",
      " |  \n",
      " |  __exit__(...)\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  fileno(self, /)\n",
      " |      Returns underlying file descriptor if one exists.\n",
      " |      \n",
      " |      OSError is raised if the IO object does not use a file descriptor.\n",
      " |  \n",
      " |  flush(self, /)\n",
      " |      Flush write buffers, if applicable.\n",
      " |      \n",
      " |      This is not implemented for read-only and non-blocking streams.\n",
      " |  \n",
      " |  isatty(self, /)\n",
      " |      Return whether this is an 'interactive' stream.\n",
      " |      \n",
      " |      Return False if it can't be determined.\n",
      " |  \n",
      " |  readlines(self, hint=-1, /)\n",
      " |      Return a list of lines from the stream.\n",
      " |      \n",
      " |      hint can be specified to control the number of lines read: no more\n",
      " |      lines will be read if the total size (in bytes/characters) of all\n",
      " |      lines so far exceeds hint.\n",
      " |  \n",
      " |  writelines(self, lines, /)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _IOBase:\n",
      " |  \n",
      " |  __dict__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StringIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFile = StringIO()\n",
    "testFile.write(\"{'a':1}\")\n",
    "testFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.StringIO"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile = StringIO()\n",
    "testFile.write(\"StringIO enables us to use IO interface without a real file object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StringIO enables us to use IO interface without a real file object.'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package json:\n",
      "\n",
      "NAME\n",
      "    json\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.6/library/json\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    JSON (JavaScript Object Notation) <http://json.org> is a subset of\n",
      "    JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\n",
      "    interchange format.\n",
      "    \n",
      "    :mod:`json` exposes an API familiar to users of the standard library\n",
      "    :mod:`marshal` and :mod:`pickle` modules.  It is derived from a\n",
      "    version of the externally maintained simplejson library.\n",
      "    \n",
      "    Encoding basic Python object hierarchies::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n",
      "        '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n",
      "        >>> print(json.dumps(\"\\\"foo\\bar\"))\n",
      "        \"\\\"foo\\bar\"\n",
      "        >>> print(json.dumps('\\u1234'))\n",
      "        \"\\u1234\"\n",
      "        >>> print(json.dumps('\\\\'))\n",
      "        \"\\\\\"\n",
      "        >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n",
      "        {\"a\": 0, \"b\": 0, \"c\": 0}\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO()\n",
      "        >>> json.dump(['streaming API'], io)\n",
      "        >>> io.getvalue()\n",
      "        '[\"streaming API\"]'\n",
      "    \n",
      "    Compact encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> from collections import OrderedDict\n",
      "        >>> mydict = OrderedDict([('4', 5), ('6', 7)])\n",
      "        >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n",
      "        '[1,2,3,{\"4\":5,\"6\":7}]'\n",
      "    \n",
      "    Pretty printing::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n",
      "        {\n",
      "            \"4\": 5,\n",
      "            \"6\": 7\n",
      "        }\n",
      "    \n",
      "    Decoding JSON::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n",
      "        >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n",
      "        True\n",
      "        >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n",
      "        True\n",
      "        >>> from io import StringIO\n",
      "        >>> io = StringIO('[\"streaming API\"]')\n",
      "        >>> json.load(io)[0] == 'streaming API'\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object decoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def as_complex(dct):\n",
      "        ...     if '__complex__' in dct:\n",
      "        ...         return complex(dct['real'], dct['imag'])\n",
      "        ...     return dct\n",
      "        ...\n",
      "        >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n",
      "        ...     object_hook=as_complex)\n",
      "        (1+2j)\n",
      "        >>> from decimal import Decimal\n",
      "        >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n",
      "        True\n",
      "    \n",
      "    Specializing JSON object encoding::\n",
      "    \n",
      "        >>> import json\n",
      "        >>> def encode_complex(obj):\n",
      "        ...     if isinstance(obj, complex):\n",
      "        ...         return [obj.real, obj.imag]\n",
      "        ...     raise TypeError(repr(obj) + \" is not JSON serializable\")\n",
      "        ...\n",
      "        >>> json.dumps(2 + 1j, default=encode_complex)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n",
      "        '[2.0, 1.0]'\n",
      "        >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n",
      "        '[2.0, 1.0]'\n",
      "    \n",
      "    \n",
      "    Using json.tool from the shell to validate and pretty-print::\n",
      "    \n",
      "        $ echo '{\"json\":\"obj\"}' | python -m json.tool\n",
      "        {\n",
      "            \"json\": \"obj\"\n",
      "        }\n",
      "        $ echo '{ 1.2:3.4}' | python -m json.tool\n",
      "        Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    decoder\n",
      "    encoder\n",
      "    scanner\n",
      "    tool\n",
      "\n",
      "CLASSES\n",
      "    builtins.ValueError(builtins.Exception)\n",
      "        json.decoder.JSONDecodeError\n",
      "    builtins.object\n",
      "        json.decoder.JSONDecoder\n",
      "        json.encoder.JSONEncoder\n",
      "    \n",
      "    class JSONDecodeError(builtins.ValueError)\n",
      "     |  Subclass of ValueError with the following additional properties:\n",
      "     |  \n",
      "     |  msg: The unformatted error message\n",
      "     |  doc: The JSON document being parsed\n",
      "     |  pos: The start index of doc where parsing failed\n",
      "     |  lineno: The line corresponding to pos\n",
      "     |  colno: The column corresponding to pos\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JSONDecodeError\n",
      "     |      builtins.ValueError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, doc, pos)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.ValueError:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class JSONDecoder(builtins.object)\n",
      "     |  Simple JSON <http://json.org> decoder\n",
      "     |  \n",
      "     |  Performs the following translations in decoding by default:\n",
      "     |  \n",
      "     |  +---------------+-------------------+\n",
      "     |  | JSON          | Python            |\n",
      "     |  +===============+===================+\n",
      "     |  | object        | dict              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | array         | list              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | string        | str               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (int)  | int               |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | number (real) | float             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | true          | True              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | false         | False             |\n",
      "     |  +---------------+-------------------+\n",
      "     |  | null          | None              |\n",
      "     |  +---------------+-------------------+\n",
      "     |  \n",
      "     |  It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as\n",
      "     |  their corresponding ``float`` values, which is outside the JSON spec.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)\n",
      "     |      ``object_hook``, if specified, will be called with the result\n",
      "     |      of every JSON object decoded and its return value will be used in\n",
      "     |      place of the given ``dict``.  This can be used to provide custom\n",
      "     |      deserializations (e.g. to support JSON-RPC class hinting).\n",
      "     |      \n",
      "     |      ``object_pairs_hook``, if specified will be called with the result of\n",
      "     |      every JSON object decoded with an ordered list of pairs.  The return\n",
      "     |      value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "     |      This feature can be used to implement custom decoders that rely on the\n",
      "     |      order that the key and value pairs are decoded (for example,\n",
      "     |      collections.OrderedDict will remember the order of insertion). If\n",
      "     |      ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n",
      "     |      priority.\n",
      "     |      \n",
      "     |      ``parse_float``, if specified, will be called with the string\n",
      "     |      of every JSON float to be decoded. By default this is equivalent to\n",
      "     |      float(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON floats (e.g. decimal.Decimal).\n",
      "     |      \n",
      "     |      ``parse_int``, if specified, will be called with the string\n",
      "     |      of every JSON int to be decoded. By default this is equivalent to\n",
      "     |      int(num_str). This can be used to use another datatype or parser\n",
      "     |      for JSON integers (e.g. float).\n",
      "     |      \n",
      "     |      ``parse_constant``, if specified, will be called with one of the\n",
      "     |      following strings: -Infinity, Infinity, NaN.\n",
      "     |      This can be used to raise an exception if invalid JSON numbers\n",
      "     |      are encountered.\n",
      "     |      \n",
      "     |      If ``strict`` is false (true is the default), then control\n",
      "     |      characters will be allowed inside strings.  Control characters in\n",
      "     |      this context are those with character codes in the 0-31 range,\n",
      "     |      including ``'\\t'`` (tab), ``'\\n'``, ``'\\r'`` and ``'\\0'``.\n",
      "     |  \n",
      "     |  decode(self, s, _w=<built-in method match of _sre.SRE_Pattern object at 0x10bc2ddb0>)\n",
      "     |      Return the Python representation of ``s`` (a ``str`` instance\n",
      "     |      containing a JSON document).\n",
      "     |  \n",
      "     |  raw_decode(self, s, idx=0)\n",
      "     |      Decode a JSON document from ``s`` (a ``str`` beginning with\n",
      "     |      a JSON document) and return a 2-tuple of the Python\n",
      "     |      representation and the index in ``s`` where the document ended.\n",
      "     |      \n",
      "     |      This can be used to decode a JSON document from a string that may\n",
      "     |      have extraneous data at the end.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class JSONEncoder(builtins.object)\n",
      "     |  Extensible JSON <http://json.org> encoder for Python data structures.\n",
      "     |  \n",
      "     |  Supports the following objects and types by default:\n",
      "     |  \n",
      "     |  +-------------------+---------------+\n",
      "     |  | Python            | JSON          |\n",
      "     |  +===================+===============+\n",
      "     |  | dict              | object        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | list, tuple       | array         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | str               | string        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | int, float        | number        |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | True              | true          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | False             | false         |\n",
      "     |  +-------------------+---------------+\n",
      "     |  | None              | null          |\n",
      "     |  +-------------------+---------------+\n",
      "     |  \n",
      "     |  To extend this to recognize other objects, subclass and implement a\n",
      "     |  ``.default()`` method with another method that returns a serializable\n",
      "     |  object for ``o`` if possible, otherwise it should call the superclass\n",
      "     |  implementation (to raise ``TypeError``).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)\n",
      "     |      Constructor for JSONEncoder, with sensible defaults.\n",
      "     |      \n",
      "     |      If skipkeys is false, then it is a TypeError to attempt\n",
      "     |      encoding of keys that are not str, int, float or None.  If\n",
      "     |      skipkeys is True, such items are simply skipped.\n",
      "     |      \n",
      "     |      If ensure_ascii is true, the output is guaranteed to be str\n",
      "     |      objects with all incoming non-ASCII characters escaped.  If\n",
      "     |      ensure_ascii is false, the output can contain non-ASCII characters.\n",
      "     |      \n",
      "     |      If check_circular is true, then lists, dicts, and custom encoded\n",
      "     |      objects will be checked for circular references during encoding to\n",
      "     |      prevent an infinite recursion (which would cause an OverflowError).\n",
      "     |      Otherwise, no such check takes place.\n",
      "     |      \n",
      "     |      If allow_nan is true, then NaN, Infinity, and -Infinity will be\n",
      "     |      encoded as such.  This behavior is not JSON specification compliant,\n",
      "     |      but is consistent with most JavaScript based encoders and decoders.\n",
      "     |      Otherwise, it will be a ValueError to encode such floats.\n",
      "     |      \n",
      "     |      If sort_keys is true, then the output of dictionaries will be\n",
      "     |      sorted by key; this is useful for regression tests to ensure\n",
      "     |      that JSON serializations can be compared on a day-to-day basis.\n",
      "     |      \n",
      "     |      If indent is a non-negative integer, then JSON array\n",
      "     |      elements and object members will be pretty-printed with that\n",
      "     |      indent level.  An indent level of 0 will only insert newlines.\n",
      "     |      None is the most compact representation.\n",
      "     |      \n",
      "     |      If specified, separators should be an (item_separator, key_separator)\n",
      "     |      tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n",
      "     |      (',', ': ') otherwise.  To get the most compact JSON representation,\n",
      "     |      you should specify (',', ':') to eliminate whitespace.\n",
      "     |      \n",
      "     |      If specified, default is a function that gets called for objects\n",
      "     |      that can't otherwise be serialized.  It should return a JSON encodable\n",
      "     |      version of the object or raise a ``TypeError``.\n",
      "     |  \n",
      "     |  default(self, o)\n",
      "     |      Implement this method in a subclass such that it returns\n",
      "     |      a serializable object for ``o``, or calls the base implementation\n",
      "     |      (to raise a ``TypeError``).\n",
      "     |      \n",
      "     |      For example, to support arbitrary iterators, you could\n",
      "     |      implement default like this::\n",
      "     |      \n",
      "     |          def default(self, o):\n",
      "     |              try:\n",
      "     |                  iterable = iter(o)\n",
      "     |              except TypeError:\n",
      "     |                  pass\n",
      "     |              else:\n",
      "     |                  return list(iterable)\n",
      "     |              # Let the base class default method raise the TypeError\n",
      "     |              return JSONEncoder.default(self, o)\n",
      "     |  \n",
      "     |  encode(self, o)\n",
      "     |      Return a JSON string representation of a Python data structure.\n",
      "     |      \n",
      "     |      >>> from json.encoder import JSONEncoder\n",
      "     |      >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n",
      "     |      '{\"foo\": [\"bar\", \"baz\"]}'\n",
      "     |  \n",
      "     |  iterencode(self, o, _one_shot=False)\n",
      "     |      Encode the given object and yield each string\n",
      "     |      representation as available.\n",
      "     |      \n",
      "     |      For example::\n",
      "     |      \n",
      "     |          for chunk in JSONEncoder().iterencode(bigobject):\n",
      "     |              mysocket.write(chunk)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  item_separator = ', '\n",
      "     |  \n",
      "     |  key_separator = ': '\n",
      "\n",
      "FUNCTIONS\n",
      "    dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "        ``.write()``-supporting file-like object).\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "        contain non-ASCII characters if they appear in strings contained in\n",
      "        ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "        in strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "        Serialize ``obj`` to a JSON formatted ``str``.\n",
      "        \n",
      "        If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "        (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "        instead of raising a ``TypeError``.\n",
      "        \n",
      "        If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n",
      "        characters if they appear in strings contained in ``obj``. Otherwise, all\n",
      "        such characters are escaped in JSON strings.\n",
      "        \n",
      "        If ``check_circular`` is false, then the circular reference check\n",
      "        for container types will be skipped and a circular reference will\n",
      "        result in an ``OverflowError`` (or worse).\n",
      "        \n",
      "        If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n",
      "        strict compliance of the JSON specification, instead of using the\n",
      "        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "        \n",
      "        If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "        object members will be pretty-printed with that indent level. An indent\n",
      "        level of 0 will only insert newlines. ``None`` is the most compact\n",
      "        representation.\n",
      "        \n",
      "        If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "        tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "        ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "        you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "        \n",
      "        ``default(obj)`` is a function that should return a serializable version\n",
      "        of obj or raise TypeError. The default simply raises TypeError.\n",
      "        \n",
      "        If *sort_keys* is true (default: ``False``), then the output of\n",
      "        dictionaries will be sorted by key.\n",
      "        \n",
      "        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "        ``.default()`` method to serialize additional types), specify it with\n",
      "        the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "    \n",
      "    load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n",
      "        a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders that rely on the\n",
      "        order that the key and value pairs are decoded (for example,\n",
      "        collections.OrderedDict will remember the order of insertion). If\n",
      "        ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "    \n",
      "    loads(s, *, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)\n",
      "        Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n",
      "        containing a JSON document) to a Python object.\n",
      "        \n",
      "        ``object_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decode (a ``dict``). The return value of\n",
      "        ``object_hook`` will be used instead of the ``dict``. This feature\n",
      "        can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n",
      "        \n",
      "        ``object_pairs_hook`` is an optional function that will be called with the\n",
      "        result of any object literal decoded with an ordered list of pairs.  The\n",
      "        return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n",
      "        This feature can be used to implement custom decoders that rely on the\n",
      "        order that the key and value pairs are decoded (for example,\n",
      "        collections.OrderedDict will remember the order of insertion). If\n",
      "        ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.\n",
      "        \n",
      "        ``parse_float``, if specified, will be called with the string\n",
      "        of every JSON float to be decoded. By default this is equivalent to\n",
      "        float(num_str). This can be used to use another datatype or parser\n",
      "        for JSON floats (e.g. decimal.Decimal).\n",
      "        \n",
      "        ``parse_int``, if specified, will be called with the string\n",
      "        of every JSON int to be decoded. By default this is equivalent to\n",
      "        int(num_str). This can be used to use another datatype or parser\n",
      "        for JSON integers (e.g. float).\n",
      "        \n",
      "        ``parse_constant``, if specified, will be called with one of the\n",
      "        following strings: -Infinity, Infinity, NaN.\n",
      "        This can be used to raise an exception if invalid JSON numbers\n",
      "        are encountered.\n",
      "        \n",
      "        To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n",
      "        kwarg; otherwise ``JSONDecoder`` is used.\n",
      "        \n",
      "        The ``encoding`` argument is ignored and deprecated.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['dump', 'dumps', 'load', 'loads', 'JSONDecoder', 'JSONDecod...\n",
      "\n",
      "VERSION\n",
      "    2.0.9\n",
      "\n",
      "AUTHOR\n",
      "    Bob Ippolito <bob@redivi.com>\n",
      "\n",
      "FILE\n",
      "    /Users/bdsaglam/anaconda3/lib/python3.6/json/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_list = json.dumps([1, 'simple', 'list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('simple_list.json', 'w') as f:\n",
    "    json.dump(simple_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('simple_list.json', 'r') as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, \"simple\", \"list\"]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Ali\": \"5321234567\", \"Veli\": \"5323180091\"}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonebook = {\"Ali\": \"5321234567\", \"Veli\": \"5323180091\"}\n",
    "json.dumps(phonebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('phonebook.json', 'w') as f:\n",
    "    json.dump(phonebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('phonebook.json', 'r') as f:\n",
    "    x = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ali': '5321234567', 'Veli': '5323180091'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured file reading and writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../io/populations_tab.txt', 'r') as f:\n",
    "    data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# year\\thare\\tlynx\\tcarrot',\n",
       " '1900\\t30e3\\t4e3\\t48300',\n",
       " '1901\\t47.2e3\\t6.1e3\\t48200',\n",
       " '1902\\t70.2e3\\t9.8e3\\t41500',\n",
       " '1903\\t77.4e3\\t35.2e3\\t38200',\n",
       " '1904\\t36.3e3\\t59.4e3\\t40600',\n",
       " '1905\\t20.6e3\\t41.7e3\\t39800',\n",
       " '1906\\t18.1e3\\t19e3\\t38600',\n",
       " '1907\\t21.4e3\\t13e3\\t42300',\n",
       " '1908\\t22e3\\t8.3e3\\t44500',\n",
       " '1909\\t25.4e3\\t9.1e3\\t42100',\n",
       " '1910\\t27.1e3\\t7.4e3\\t46000',\n",
       " '1911\\t40.3e3\\t8e3\\t46800',\n",
       " '1912\\t57e3\\t12.3e3\\t43800',\n",
       " '1913\\t76.6e3\\t19.5e3\\t40900',\n",
       " '1914\\t52.3e3\\t45.7e3\\t39400',\n",
       " '1915\\t19.5e3\\t51.1e3\\t39000',\n",
       " '1916\\t11.2e3\\t29.7e3\\t36700',\n",
       " '1917\\t7.6e3\\t15.8e3\\t41800',\n",
       " '1918\\t14.6e3\\t9.7e3\\t43300',\n",
       " '1919\\t16.2e3\\t10.1e3\\t41300',\n",
       " '1920\\t24.7e3\\t8.6e3\\t47300']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = []\n",
    "for item in data[1:]:\n",
    "    record = item.split('\\t')\n",
    "    year = int(record[0])\n",
    "    \n",
    "    seq.append(tuple(float(field) for field in record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1900.0, 30000.0, 4000.0, 48300.0),\n",
       " (1901.0, 47200.0, 6100.0, 48200.0),\n",
       " (1902.0, 70200.0, 9800.0, 41500.0),\n",
       " (1903.0, 77400.0, 35200.0, 38200.0),\n",
       " (1904.0, 36300.0, 59400.0, 40600.0),\n",
       " (1905.0, 20600.0, 41700.0, 39800.0),\n",
       " (1906.0, 18100.0, 19000.0, 38600.0),\n",
       " (1907.0, 21400.0, 13000.0, 42300.0),\n",
       " (1908.0, 22000.0, 8300.0, 44500.0),\n",
       " (1909.0, 25400.0, 9100.0, 42100.0),\n",
       " (1910.0, 27100.0, 7400.0, 46000.0),\n",
       " (1911.0, 40300.0, 8000.0, 46800.0),\n",
       " (1912.0, 57000.0, 12300.0, 43800.0),\n",
       " (1913.0, 76600.0, 19500.0, 40900.0),\n",
       " (1914.0, 52300.0, 45700.0, 39400.0),\n",
       " (1915.0, 19500.0, 51100.0, 39000.0),\n",
       " (1916.0, 11200.0, 29700.0, 36700.0),\n",
       " (1917.0, 7600.0, 15800.0, 41800.0),\n",
       " (1918.0, 14600.0, 9700.0, 43300.0),\n",
       " (1919.0, 16200.0, 10100.0, 41300.0),\n",
       " (1920.0, 24700.0, 8600.0, 47300.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ed5a8dcfe00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "dt = [tuple(float(col) for col in row) for row in [tuple(item.split('\\t')) for item in data[1:]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1900.0, 30000.0, 4000.0, 48300.0),\n",
       " (1901.0, 47200.0, 6100.0, 48200.0),\n",
       " (1902.0, 70200.0, 9800.0, 41500.0),\n",
       " (1903.0, 77400.0, 35200.0, 38200.0),\n",
       " (1904.0, 36300.0, 59400.0, 40600.0),\n",
       " (1905.0, 20600.0, 41700.0, 39800.0),\n",
       " (1906.0, 18100.0, 19000.0, 38600.0),\n",
       " (1907.0, 21400.0, 13000.0, 42300.0),\n",
       " (1908.0, 22000.0, 8300.0, 44500.0),\n",
       " (1909.0, 25400.0, 9100.0, 42100.0),\n",
       " (1910.0, 27100.0, 7400.0, 46000.0),\n",
       " (1911.0, 40300.0, 8000.0, 46800.0),\n",
       " (1912.0, 57000.0, 12300.0, 43800.0),\n",
       " (1913.0, 76600.0, 19500.0, 40900.0),\n",
       " (1914.0, 52300.0, 45700.0, 39400.0),\n",
       " (1915.0, 19500.0, 51100.0, 39000.0),\n",
       " (1916.0, 11200.0, 29700.0, 36700.0),\n",
       " (1917.0, 7600.0, 15800.0, 41800.0),\n",
       " (1918.0, 14600.0, 9700.0, 43300.0),\n",
       " (1919.0, 16200.0, 10100.0, 41300.0),\n",
       " (1920.0, 24700.0, 8600.0, 47300.0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../io/populations_fixedwidth.txt', 'w') as f:\n",
    "    for row in dt:\n",
    "        line = \"{:<8.0f}{:>16.3f}{:>16.2f}{:>16.2f}\\n\".format(*row)\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900           30000.000         4000.00        48300.00\n",
      "\n",
      "1901           47200.000         6100.00        48200.00\n",
      "\n",
      "1902           70200.000         9800.00        41500.00\n",
      "\n",
      "1903           77400.000        35200.00        38200.00\n",
      "\n",
      "1904           36300.000        59400.00        40600.00\n",
      "\n",
      "1905           20600.000        41700.00        39800.00\n",
      "\n",
      "1906           18100.000        19000.00        38600.00\n",
      "\n",
      "1907           21400.000        13000.00        42300.00\n",
      "\n",
      "1908           22000.000         8300.00        44500.00\n",
      "\n",
      "1909           25400.000         9100.00        42100.00\n",
      "\n",
      "1910           27100.000         7400.00        46000.00\n",
      "\n",
      "1911           40300.000         8000.00        46800.00\n",
      "\n",
      "1912           57000.000        12300.00        43800.00\n",
      "\n",
      "1913           76600.000        19500.00        40900.00\n",
      "\n",
      "1914           52300.000        45700.00        39400.00\n",
      "\n",
      "1915           19500.000        51100.00        39000.00\n",
      "\n",
      "1916           11200.000        29700.00        36700.00\n",
      "\n",
      "1917            7600.000        15800.00        41800.00\n",
      "\n",
      "1918           14600.000         9700.00        43300.00\n",
      "\n",
      "1919           16200.000        10100.00        41300.00\n",
      "\n",
      "1920           24700.000         8600.00        47300.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../io/populations_fixedwidth.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [(0, 8),\n",
    "        (8, 24),\n",
    "        (24, 40),\n",
    "        (40, 56),]\n",
    "\n",
    "df = []\n",
    "with open('../io/populations_fixedwidth.txt', \"r\") as f:\n",
    "    for line in f:\n",
    "        row = tuple(float(line[col[0]:col[1]].strip()) for col in cols)\n",
    "        df.append(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1900.0, 30000.0, 4000.0, 48300.0),\n",
       " (1901.0, 47200.0, 6100.0, 48200.0),\n",
       " (1902.0, 70200.0, 9800.0, 41500.0),\n",
       " (1903.0, 77400.0, 35200.0, 38200.0),\n",
       " (1904.0, 36300.0, 59400.0, 40600.0),\n",
       " (1905.0, 20600.0, 41700.0, 39800.0),\n",
       " (1906.0, 18100.0, 19000.0, 38600.0),\n",
       " (1907.0, 21400.0, 13000.0, 42300.0),\n",
       " (1908.0, 22000.0, 8300.0, 44500.0),\n",
       " (1909.0, 25400.0, 9100.0, 42100.0),\n",
       " (1910.0, 27100.0, 7400.0, 46000.0),\n",
       " (1911.0, 40300.0, 8000.0, 46800.0),\n",
       " (1912.0, 57000.0, 12300.0, 43800.0),\n",
       " (1913.0, 76600.0, 19500.0, 40900.0),\n",
       " (1914.0, 52300.0, 45700.0, 39400.0),\n",
       " (1915.0, 19500.0, 51100.0, 39000.0),\n",
       " (1916.0, 11200.0, 29700.0, 36700.0),\n",
       " (1917.0, 7600.0, 15800.0, 41800.0),\n",
       " (1918.0, 14600.0, 9700.0, 43300.0),\n",
       " (1919.0, 16200.0, 10100.0, 41300.0),\n",
       " (1920.0, 24700.0, 8600.0, 47300.0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module csv:\n",
      "\n",
      "NAME\n",
      "    csv - CSV parsing and writing.\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.6/library/csv\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    This module provides classes that assist in the reading and writing\n",
      "    of Comma Separated Value (CSV) files, and implements the interface\n",
      "    described by PEP 305.  Although many CSV files are simple to parse,\n",
      "    the format is not formally defined by a stable specification and\n",
      "    is subtle enough that parsing lines of a CSV file with something\n",
      "    like line.split(\",\") is bound to fail.  The module supports three\n",
      "    basic APIs: reading, writing, and registration of dialects.\n",
      "    \n",
      "    \n",
      "    DIALECT REGISTRATION:\n",
      "    \n",
      "    Readers and writers support a dialect argument, which is a convenient\n",
      "    handle on a group of settings.  When the dialect argument is a string,\n",
      "    it identifies one of the dialects previously registered with the module.\n",
      "    If it is a class or instance, the attributes of the argument are used as\n",
      "    the settings for the reader or writer:\n",
      "    \n",
      "        class excel:\n",
      "            delimiter = ','\n",
      "            quotechar = '\"'\n",
      "            escapechar = None\n",
      "            doublequote = True\n",
      "            skipinitialspace = False\n",
      "            lineterminator = '\\r\\n'\n",
      "            quoting = QUOTE_MINIMAL\n",
      "    \n",
      "    SETTINGS:\n",
      "    \n",
      "        * quotechar - specifies a one-character string to use as the \n",
      "            quoting character.  It defaults to '\"'.\n",
      "        * delimiter - specifies a one-character string to use as the \n",
      "            field separator.  It defaults to ','.\n",
      "        * skipinitialspace - specifies how to interpret whitespace which\n",
      "            immediately follows a delimiter.  It defaults to False, which\n",
      "            means that whitespace immediately following a delimiter is part\n",
      "            of the following field.\n",
      "        * lineterminator -  specifies the character sequence which should \n",
      "            terminate rows.\n",
      "        * quoting - controls when quotes should be generated by the writer.\n",
      "            It can take on any of the following module constants:\n",
      "    \n",
      "            csv.QUOTE_MINIMAL means only when required, for example, when a\n",
      "                field contains either the quotechar or the delimiter\n",
      "            csv.QUOTE_ALL means that quotes are always placed around fields.\n",
      "            csv.QUOTE_NONNUMERIC means that quotes are always placed around\n",
      "                fields which do not parse as integers or floating point\n",
      "                numbers.\n",
      "            csv.QUOTE_NONE means that quotes are never placed around fields.\n",
      "        * escapechar - specifies a one-character string used to escape \n",
      "            the delimiter when quoting is set to QUOTE_NONE.\n",
      "        * doublequote - controls the handling of quotes inside fields.  When\n",
      "            True, two consecutive quotes are interpreted as one during read,\n",
      "            and when writing, each quote character embedded in the data is\n",
      "            written as two quotes\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        _csv.Error\n",
      "    builtins.object\n",
      "        Dialect\n",
      "            excel\n",
      "                excel_tab\n",
      "            unix_dialect\n",
      "        DictReader\n",
      "        DictWriter\n",
      "        Sniffer\n",
      "    \n",
      "    class Dialect(builtins.object)\n",
      "     |  Describe a CSV dialect.\n",
      "     |  \n",
      "     |  This must be subclassed (see csv.excel).  Valid attributes are:\n",
      "     |  delimiter, quotechar, escapechar, doublequote, skipinitialspace,\n",
      "     |  lineterminator, quoting.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  delimiter = None\n",
      "     |  \n",
      "     |  doublequote = None\n",
      "     |  \n",
      "     |  escapechar = None\n",
      "     |  \n",
      "     |  lineterminator = None\n",
      "     |  \n",
      "     |  quotechar = None\n",
      "     |  \n",
      "     |  quoting = None\n",
      "     |  \n",
      "     |  skipinitialspace = None\n",
      "    \n",
      "    class DictReader(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, f, fieldnames=None, restkey=None, restval=None, dialect='excel', *args, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  fieldnames\n",
      "    \n",
      "    class DictWriter(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, f, fieldnames, restval='', extrasaction='raise', dialect='excel', *args, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  writeheader(self)\n",
      "     |  \n",
      "     |  writerow(self, rowdict)\n",
      "     |  \n",
      "     |  writerows(self, rowdicts)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Error(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Sniffer(builtins.object)\n",
      "     |  \"Sniffs\" the format of a CSV file (i.e. delimiter, quotechar)\n",
      "     |  Returns a Dialect object.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  has_header(self, sample)\n",
      "     |  \n",
      "     |  sniff(self, sample, delimiters=None)\n",
      "     |      Returns a dialect (or None) corresponding to the sample\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class excel(Dialect)\n",
      "     |  Describe the usual properties of Excel-generated CSV files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      excel\n",
      "     |      Dialect\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  delimiter = ','\n",
      "     |  \n",
      "     |  doublequote = True\n",
      "     |  \n",
      "     |  lineterminator = '\\r\\n'\n",
      "     |  \n",
      "     |  quotechar = '\"'\n",
      "     |  \n",
      "     |  quoting = 0\n",
      "     |  \n",
      "     |  skipinitialspace = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dialect:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dialect:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Dialect:\n",
      "     |  \n",
      "     |  escapechar = None\n",
      "    \n",
      "    class excel_tab(excel)\n",
      "     |  Describe the usual properties of Excel-generated TAB-delimited files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      excel_tab\n",
      "     |      excel\n",
      "     |      Dialect\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  delimiter = '\\t'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from excel:\n",
      "     |  \n",
      "     |  doublequote = True\n",
      "     |  \n",
      "     |  lineterminator = '\\r\\n'\n",
      "     |  \n",
      "     |  quotechar = '\"'\n",
      "     |  \n",
      "     |  quoting = 0\n",
      "     |  \n",
      "     |  skipinitialspace = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dialect:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dialect:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Dialect:\n",
      "     |  \n",
      "     |  escapechar = None\n",
      "    \n",
      "    class unix_dialect(Dialect)\n",
      "     |  Describe the usual properties of Unix-generated CSV files.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      unix_dialect\n",
      "     |      Dialect\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  delimiter = ','\n",
      "     |  \n",
      "     |  doublequote = True\n",
      "     |  \n",
      "     |  lineterminator = '\\n'\n",
      "     |  \n",
      "     |  quotechar = '\"'\n",
      "     |  \n",
      "     |  quoting = 1\n",
      "     |  \n",
      "     |  skipinitialspace = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Dialect:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Dialect:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Dialect:\n",
      "     |  \n",
      "     |  escapechar = None\n",
      "\n",
      "FUNCTIONS\n",
      "    field_size_limit(...)\n",
      "        Sets an upper limit on parsed fields.\n",
      "            csv.field_size_limit([limit])\n",
      "        \n",
      "        Returns old limit. If limit is not given, no new limit is set and\n",
      "        the old limit is returned\n",
      "    \n",
      "    get_dialect(...)\n",
      "        Return the dialect instance associated with name.\n",
      "        dialect = csv.get_dialect(name)\n",
      "    \n",
      "    list_dialects(...)\n",
      "        Return a list of all know dialect names.\n",
      "        names = csv.list_dialects()\n",
      "    \n",
      "    reader(...)\n",
      "        csv_reader = reader(iterable [, dialect='excel']\n",
      "                                [optional keyword args])\n",
      "            for row in csv_reader:\n",
      "                process(row)\n",
      "        \n",
      "        The \"iterable\" argument can be any object that returns a line\n",
      "        of input for each iteration, such as a file object or a list.  The\n",
      "        optional \"dialect\" parameter is discussed below.  The function\n",
      "        also accepts optional keyword arguments which override settings\n",
      "        provided by the dialect.\n",
      "        \n",
      "        The returned object is an iterator.  Each iteration returns a row\n",
      "        of the CSV file (which can span multiple input lines).\n",
      "    \n",
      "    register_dialect(...)\n",
      "        Create a mapping from a string name to a dialect class.\n",
      "        dialect = csv.register_dialect(name[, dialect[, **fmtparams]])\n",
      "    \n",
      "    unregister_dialect(...)\n",
      "        Delete the name/dialect mapping associated with a string name.\n",
      "        csv.unregister_dialect(name)\n",
      "    \n",
      "    writer(...)\n",
      "        csv_writer = csv.writer(fileobj [, dialect='excel']\n",
      "                                    [optional keyword args])\n",
      "            for row in sequence:\n",
      "                csv_writer.writerow(row)\n",
      "        \n",
      "            [or]\n",
      "        \n",
      "            csv_writer = csv.writer(fileobj [, dialect='excel']\n",
      "                                    [optional keyword args])\n",
      "            csv_writer.writerows(rows)\n",
      "        \n",
      "        The \"fileobj\" argument can be any object that supports the file API.\n",
      "\n",
      "DATA\n",
      "    QUOTE_ALL = 1\n",
      "    QUOTE_MINIMAL = 0\n",
      "    QUOTE_NONE = 3\n",
      "    QUOTE_NONNUMERIC = 2\n",
      "    __all__ = ['QUOTE_MINIMAL', 'QUOTE_ALL', 'QUOTE_NONNUMERIC', 'QUOTE_NO...\n",
      "\n",
      "VERSION\n",
      "    1.0\n",
      "\n",
      "FILE\n",
      "    /Users/bdsaglam/anaconda3/lib/python3.6/csv.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title 1', 'Title 2', 'Title 3']\n",
      "['1', 'a', '08/18/07']\n",
      "['2', 'b', '08/19/07']\n",
      "['3', 'c', '08/20/07']\n",
      "['4', 'd', '08/21/07']\n",
      "['5', 'e', '08/22/07']\n",
      "['6', 'f', '08/23/07']\n",
      "['7', 'g', '08/24/07']\n",
      "['8', 'h', '08/25/07']\n",
      "['9', 'i', '08/26/07']\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../io/sample.csv\", 'r')\n",
    "try:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "finally:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000 \u0001 \u0002 \u0003 \u0004 \u0005 \u0006 \u0007 \b \t \n",
      " \u000b",
      " \f",
      " \r",
      " \u000e \u000f \u0010 \u0011 \u0012 \u0013 \u0014 \u0015 \u0016 \u0017 \u0018 \u0019 \u001a \u001b \u001c",
      " \u001d",
      " \u001e",
      " \u001f   ! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; < = > ? @ A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ ` a b c d e f g h i j k l m n o p q r s t u v w x y z { | } ~       ",
      "                             ¡ ¢ £ ¤ ¥ ¦ § ¨ © ª « ¬ ­ ® ¯ ° ± ² ³ ´ µ ¶ · ¸ ¹ º » ¼ ½ ¾ ¿ À Á Â Ã Ä Å Æ Ç "
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(chr(i), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../io/sample2.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( ('Title 1', 'Title 2', 'Title 3') )\n",
    "    for i in range(10):\n",
    "        writer.writerow( (i+1, chr(ord('a') + i), '08/%02d/07' % (i+1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excel', 'excel-tab', 'unix']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.list_dialects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title 1', 'Title 2', 'Title 3']\n",
      "['1', 'first line\\nsecond line', '08/18/07']\n"
     ]
    }
   ],
   "source": [
    "csv.register_dialect('pipes', delimiter='|')\n",
    "\n",
    "with open('../io/sample3.csv', 'r') as f:\n",
    "    reader = csv.reader(f, dialect='pipes')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialect: \"escaped\"\n",
      "\n",
      "['col1,0,10/00/2010,Contains', 'special', 'chars:', '\\\\\"', ' \\\\, to be parsed\\r\\ncol1,1,10/01/2010,Contains special chars: \\\\\" ', '\\\\,', 'to', 'be', 'parsed']\n",
      "['col1,2,10/02/2010,Contains', 'special', 'chars:', '\\\\\"', ' \\\\, to be parsed\\r\\n']\n",
      "\n",
      "Dialect: \"excel\"\n",
      "\n",
      "['col1,0,10/00/2010,\"Contains', 'special', 'chars:', '', \"'\", ',', 'to', 'be', 'parsed\"']\n",
      "['col1,1,10/01/2010,\"Contains', 'special', 'chars:', '', \"'\", ',', 'to', 'be', 'parsed\"']\n",
      "['col1,2,10/02/2010,\"Contains', 'special', 'chars:', '', \"'\", ',', 'to', 'be', 'parsed\"']\n",
      "\n",
      "Dialect: \"excel-tab\"\n",
      "\n",
      "['col1\\t0\\t10/00/2010\\t\"Contains', 'special', 'chars:', '', \"'\", '\\t', 'to', 'be', 'parsed\"']\n",
      "['col1\\t1\\t10/01/2010\\t\"Contains', 'special', 'chars:', '', \"'\", '\\t', 'to', 'be', 'parsed\"']\n",
      "['col1\\t2\\t10/02/2010\\t\"Contains', 'special', 'chars:', '', \"'\", '\\t', 'to', 'be', 'parsed\"']\n",
      "\n",
      "Dialect: \"pipes\"\n",
      "\n",
      "['col1|0|10/00/2010|\"Contains', 'special', 'chars:', '', \"'\", '|', 'to', 'be', 'parsed\"']\n",
      "['col1|1|10/01/2010|\"Contains', 'special', 'chars:', '', \"'\", '|', 'to', 'be', 'parsed\"']\n",
      "['col1|2|10/02/2010|\"Contains', 'special', 'chars:', '', \"'\", '|', 'to', 'be', 'parsed\"']\n",
      "\n",
      "Dialect: \"singlequote\"\n",
      "\n",
      "['col1', '0', '10/00/2010', 'Contains special chars: \" \\' , to be parsed']\n",
      "['col1', '1', '10/01/2010', 'Contains special chars: \" \\' , to be parsed']\n",
      "['col1', '2', '10/02/2010', 'Contains special chars: \" \\' , to be parsed']\n",
      "\n",
      "Dialect: \"unix\"\n",
      "\n",
      "['col1', '0', '10/00/2010', 'Contains special chars: \" \\' , to be parsed']\n",
      "['col1', '1', '10/01/2010', 'Contains special chars: \" \\' , to be parsed']\n",
      "['col1', '2', '10/02/2010', 'Contains special chars: \" \\' , to be parsed']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "import textwrap\n",
    "\n",
    "csv.register_dialect('escaped', escapechar='\\\\', doublequote=False, quoting=csv.QUOTE_NONE)\n",
    "csv.register_dialect('singlequote', quotechar=\"'\", quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Generate sample data for all known dialects\n",
    "\n",
    "samples = []\n",
    "\n",
    "for name in sorted(csv.list_dialects()):\n",
    "    buffer = StringIO()\n",
    "    dialect = csv.get_dialect(name)\n",
    "    writer = csv.writer(buffer, dialect=dialect)\n",
    "    for i in range(3):\n",
    "        writer.writerow(('col1', i, '10/%02d/2010' % i,\n",
    "             'Contains special chars: \" \\' %s to be parsed' % dialect.delimiter))\n",
    "    samples.append( (name, dialect, buffer.getvalue()) )\n",
    "\n",
    "# Guess the dialect for a given sample, then use the results to parse\n",
    "# the data.\n",
    " \n",
    "sniffer = csv.Sniffer()\n",
    "\n",
    "for name, expected, sample in samples:\n",
    "    print('\\nDialect: \"%s\"\\n' % name)\n",
    "\n",
    "    dialect = sniffer.sniff(sample)\n",
    "\n",
    "    reader = csv.reader(StringIO(sample), dialect=dialect)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Excel file reading and writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [(0, 8),\n",
    "        (8, 24),\n",
    "        (24, 40),\n",
    "        (40, 56),]\n",
    "\n",
    "df = []\n",
    "with open('../io/populations_fixedwidth.txt', \"r\") as f:\n",
    "    for line in f:\n",
    "        row = tuple(float(line[col[0]:col[1]].strip()) for col in cols)\n",
    "        df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1900.0, 30000.0, 4000.0, 48300.0),\n",
       " (1901.0, 47200.0, 6100.0, 48200.0),\n",
       " (1902.0, 70200.0, 9800.0, 41500.0),\n",
       " (1903.0, 77400.0, 35200.0, 38200.0),\n",
       " (1904.0, 36300.0, 59400.0, 40600.0),\n",
       " (1905.0, 20600.0, 41700.0, 39800.0),\n",
       " (1906.0, 18100.0, 19000.0, 38600.0),\n",
       " (1907.0, 21400.0, 13000.0, 42300.0),\n",
       " (1908.0, 22000.0, 8300.0, 44500.0),\n",
       " (1909.0, 25400.0, 9100.0, 42100.0),\n",
       " (1910.0, 27100.0, 7400.0, 46000.0),\n",
       " (1911.0, 40300.0, 8000.0, 46800.0),\n",
       " (1912.0, 57000.0, 12300.0, 43800.0),\n",
       " (1913.0, 76600.0, 19500.0, 40900.0),\n",
       " (1914.0, 52300.0, 45700.0, 39400.0),\n",
       " (1915.0, 19500.0, 51100.0, 39000.0),\n",
       " (1916.0, 11200.0, 29700.0, 36700.0),\n",
       " (1917.0, 7600.0, 15800.0, 41800.0),\n",
       " (1918.0, 14600.0, 9700.0, 43300.0),\n",
       " (1919.0, 16200.0, 10100.0, 41300.0),\n",
       " (1920.0, 24700.0, 8600.0, 47300.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "\n",
    "# grab the active worksheet\n",
    "ws = wb.active\n",
    "\n",
    "# Data can be assigned directly to cells\n",
    "ws['A1'] = 42\n",
    "\n",
    "# Rows can also be appended\n",
    "ws.append([1, 2, 3])\n",
    "\n",
    "# Python types will automatically be converted\n",
    "import datetime\n",
    "ws['A2'] = datetime.datetime.now()\n",
    "\n",
    "# Save the file\n",
    "wb.save(\"../io/sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "wb = Workbook()\n",
    "\n",
    "dest_filename = '../io/empty_book.xlsx'\n",
    "\n",
    "ws1 = wb.active\n",
    "ws1.title = \"range names\"\n",
    "\n",
    "for row in range(1, 40):\n",
    "    ws1.append(range(600))\n",
    "\n",
    "ws2 = wb.t(title=\"Pi\")\n",
    "\n",
    "ws2['F5'] = 3.14\n",
    "hgws3 = wb.create_sheet(title=\"Data\")\n",
    "for row in range(10, 20):\n",
    "    for col in range(27, 54):\n",
    "        _ = ws3.cell(column=col, row=row, value=\"{0}\".format(get_column_letter(col)))\n",
    "        \n",
    "print(ws3['AA10'].value)\n",
    "wb.save(filename = dest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(filename = '../io/empty_book.xlsx')\n",
    "sheet_ranges = wb['range names']\n",
    "print(sheet_ranges['D18'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yyyy-mm-dd h:mm:ss\n",
      "0.031400000000000004\n",
      "0%\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "# set date using a Python datetime\n",
    "ws['A1'] = datetime.datetime(2010, 7, 21)\n",
    "print(ws['A1'].number_format)\n",
    "\n",
    "# You can enable type inference on a case-by-case basis\n",
    "wb.guess_types = True\n",
    "\n",
    "# set percentage using a string followed by the percent sign\n",
    "ws['B1'] = '3.14%'\n",
    "wb.guess_types = False\n",
    "print(ws['B1'].value)\n",
    "print(ws['B1'].number_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "# add a simple formula\n",
    "ws[\"A1\"] = \"=SUM(1, 1)\"\n",
    "wb.save(\"../io/formula.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openpyxl.workbook import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "ws.merge_cells('A2:D2')\n",
    "ws.unmerge_cells('A2:D2')\n",
    "\n",
    "# or equivalently\n",
    "ws.merge_cells(start_row=2, start_column=1, end_row=4, end_column=4)\n",
    "ws.unmerge_cells(start_row=2, start_column=1, end_row=4, end_column=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
